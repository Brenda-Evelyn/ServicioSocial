{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos a traves de librería pandas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librerias que voy a usar\n",
    "import pandas as pd    #Contiene los metodos para leer csv, excel, etc.\n",
    "import os              #Contiene el metodo para unir rutas de ubicacion de los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainpath = \"C:/Users/jvill/Documents/ESCUELA/Machine Learning/Datasets\"  # Ruta global que voy a usar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo1: pandas.read_csv()  - Titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leer base de datos\n",
    "ruta1 = \"titanic/titanic3.csv\"\n",
    "#El siguiente método de la librería os junta las rutas dadas y las arregla y/o corrige para devolver una ruta correcta.\n",
    "#El método read_scv simplemente lee la ruta de adentro de los parentesis.\n",
    "datos1 = pd.read_csv(os.path.join(mainpath,ruta1))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo2: pandas.read_csv() - Churn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta2 = \"customer-churn-model/Customer Churn Model.txt\"        # Otra ruta que voy a usar\n",
    "datos2 =pd.read_csv(os.path.join(mainpath,ruta2))              # leer base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver los nombres de las columnas del dataframe\n",
    "datos2.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambiar los nombres de las columnas de Churn Model por los nombres dados en otro archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#otra ruta que voy a usar para leer los nombres de las columnas\n",
    "ruta3 = \"customer-churn-model/Customer Churn Columns.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leer otro archivo csv conformado solamente por los nombres de las columnas\n",
    "nombres = pd.read_csv(os.path.join(mainpath,ruta3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tomo la columna llamada Column_Names del archivo nombres y la convierto a lista\n",
    "lista = nombres[\"Column_Names\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vuelvo a leer la base de datos pero ahora le paso como nombres de columnas mi lista\n",
    "datos3 = pd.read_csv(os.path.join(mainpath,ruta2),header=None,names=lista)\n",
    "datos3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora voy a borrar el primer renglon de datos de la tabla, porque son los nombres de las columnas anteriores\n",
    "datos3 = datos3.drop([0])   #Aqui borro el primer renglon\n",
    "datos3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Por fin tengo los nombres de las columnas que quería:\n",
    "datos3.columns.values  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de datos a través de método open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta4=\"customer-churn-model/Customer Churn Model.txt\" #nueva ruta para leer mi archivo .txt\n",
    "datos4 = open(os.path.join(mainpath,ruta4),\"r\")       #abro el archivo sólo para lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=datos4.readline().strip().split(\",\")      # leo los nombres de las columnas\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_col=len(names)\n",
    "print(n_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dic={}\n",
    "for col in names:\n",
    "    main_dic[col]=[] #Creo un diccionario en donde cada campo significará una columna de la tabla\n",
    "main_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for line in datos4:\n",
    "    renglon=line.strip().split(\",\")     #Leo cada linea y separo sus campos que traen comas como separador\n",
    "    for i in range(n_col):\n",
    "        main_dic[names[i]].append(renglon[i])  #agrego todos los campos de la linea al diccionario\n",
    "    counter += 1\n",
    "print(main_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=\"La tabla de datos tiene {} renglones y {} columnas\"\n",
    "print(t.format(counter,n_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4= pd.DataFrame(main_dic) #Convierto el diccionario a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura y escritura de ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = mainpath + \"/customer-churn-model/Customer Churn Model.txt\"\n",
    "outfile = mainpath + \"/customer-churn-model/Tab Customer Churn Model.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(infile,\"r\") as infile1:\n",
    "    with open(outfile,\"w\") as outfile1:\n",
    "        for line in infile1:\n",
    "            fields = line.strip().split(\",\")    #Leo cada linea del archivo infile1 y la separo cada que hay una coma.\n",
    "            outfile1.write(\"\\t\".join(fields))   #Vuelvo a unir la linea de arriba pero en cada separación pongo un tabulador.\n",
    "                                                #Luego escribo la línea,ya unida mediante tabuladores, en el archivo outfile1\n",
    "            outfile1.write(\"\\n\")                #Escribo salto de línea, para que pase al siguiente renglon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv(outfile,sep = \"\\t\")\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leer archivo de url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_url = \"http://winterolympicsmedals.com/medals.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usando paquete pandas, metodo read_csv\n",
    "datos5 = pd.read_csv(my_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EJERCICIO DE TAREA DEL VIDEO 27\n",
    "\n",
    "#Usando paquete urllib3\n",
    "import urllib3\n",
    "http = urllib3.PoolManager()\n",
    "r = http.request(\"GET\",my_url)\n",
    "response = r.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response   #Todo lo leyó como un renglón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(response))  #La respuesta es tipo byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lo paso a tabla\n",
    "linea = str(response,'ascii')    #la transformo a string\n",
    "print(linea)                     #visualizo mi string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = mainpath+\"/Prueba-Medallas/medallas.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(archivo,\"w\") as outfile2:\n",
    "    for renglon in linea:\n",
    "        outfile2.write(renglon)    #Escribo cada renglon del string como un renglon del nuevo archivo .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = pd.read_csv(archivo)        #Ahora leo mi archivo nuevo .txt normalmente con pandas\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ficheros xls y xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta5 = \"/titanic/titanic3.xls\"   #Nueva ruta de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos un archivo de excel (xls o xlsx) con la libreria pandas:\n",
    "titanic2 = pd.read_excel(mainpath + ruta5,\"titanic3\")    # El segundo parámetro \"titanic3\" es la pestaña del excel\n",
    "titanic3 = pd.read_excel(mainpath + ruta5,\"titanic3\")    # Creamos otro dataframe igual pero con otro nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esribimos los dataframes a otros tipos de archivos\n",
    "titanic2.to_csv(mainpath + \"/titanic/prueba_csv.csv\")      #Escribimos un csv\n",
    "titanic3.to_json(mainpath + \"/titanic/prueba_json.json\")   #Escribimos un json\n",
    "titanic3.to_json(mainpath + \"/titanic/prueba_xls.xls\")   #Escribimos un xls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
